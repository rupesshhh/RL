{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6jCIWGPhZob",
        "outputId": "372d6e02-5e61-4dc2-f72e-80042a01e7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Policy:\n",
            "State 0 :  Move 0 cars\n",
            "State 1 :  Move 1 cars\n",
            "State 2 :  Move 2 cars\n",
            "State 3 :  Move 3 cars\n",
            "State 4 :  Move 4 cars\n",
            "State 5 :  Move 5 cars\n",
            "State 6 :  Move 6 cars\n",
            "State 7 :  Move 7 cars\n",
            "State 8 :  Move 8 cars\n",
            "State 9 :  Move 9 cars\n",
            "State 10 :  Move 10 cars\n",
            "State 11 :  Move 10 cars\n",
            "State 12 :  Move 10 cars\n",
            "State 13 :  Move 9 cars\n",
            "State 14 :  Move 8 cars\n",
            "State 15 :  Move 7 cars\n",
            "State 16 :  Move 6 cars\n",
            "State 17 :  Move 5 cars\n",
            "State 18 :  Move 4 cars\n",
            "State 19 :  Move 3 cars\n",
            "State 20 :  Move 2 cars\n",
            "State 21 :  Move 1 cars\n",
            "\n",
            "Optimal Value Function:\n",
            "[-1.99999999e+01  7.21632608e+74  7.20594241e+74  7.19479984e+74\n",
            "  7.18596385e+74  7.18195861e+74  7.15275016e+74  7.15402283e+74\n",
            "  7.15458708e+74  7.15842558e+74  7.16313855e+74  6.84019513e+74\n",
            "  7.16313856e+74  7.15842560e+74  7.15458711e+74  7.15402287e+74\n",
            "  7.15275021e+74  7.18195868e+74  7.18596393e+74  7.19479993e+74\n",
            "  7.20594252e+74  7.21632619e+74]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "NUM_STATES = 22\n",
        "MAX_CARS = 11\n",
        "RENTAL_COST = 3\n",
        "EMPLOYEE_TRANSFER = 1\n",
        "EXTRA_PARKING_COST = 5\n",
        "DISCOUNT_FACTOR = 0.85\n",
        "\n",
        "\n",
        "def reward(state, action):\n",
        "  cars_moved = min(action, state)\n",
        "  cars_left = state - cars_moved\n",
        "  cars_right = action - cars_moved\n",
        "\n",
        "  reward = 0\n",
        "\n",
        "  if cars_moved > 0:\n",
        "    reward -= RENTAL_COST * EMPLOYEE_TRANSFER\n",
        "\n",
        "  reward += RENTAL_COST * (cars_moved - EMPLOYEE_TRANSFER)\n",
        "\n",
        "  if cars_left > MAX_CARS:\n",
        "    reward -= EXTRA_PARKING_COST\n",
        "  if cars_right > MAX_CARS:\n",
        "    reward -= EXTRA_PARKING_COST\n",
        "\n",
        "  return reward\n",
        "\n",
        "\n",
        "def transition_probability(state, action):\n",
        "  epsilon = 1e-9\n",
        "  num_actions = min(state, NUM_STATES - state)\n",
        "  if num_actions == 0:\n",
        "    num_actions = 1\n",
        "  probability = 1 / (num_actions + epsilon)\n",
        "  P = np.zeros((NUM_STATES, NUM_STATES))\n",
        "  for next_state in range(NUM_STATES):\n",
        "    if abs(next_state - state) <= action:\n",
        "      P[state, next_state] = probability\n",
        "  return P\n",
        "\n",
        "def policy_evaluation(policy, value_function, iterations=100, threshold=1e-8):\n",
        "  for _ in range(iterations):\n",
        "    new_value_function = np.zeros_like(value_function)\n",
        "    for state in range(NUM_STATES):\n",
        "      action = policy[state]\n",
        "      transition_probs = transition_probability(state, action)\n",
        "      rewards = reward(state, action)\n",
        "      new_value_function[state] = np.sum(transition_probs * (rewards + DISCOUNT_FACTOR * value_function))\n",
        "    change = np.abs(new_value_function - value_function).max()\n",
        "    value_function = new_value_function\n",
        "    if change < threshold:\n",
        "      break\n",
        "  return value_function\n",
        "\n",
        "def policy_improvement(value_function):\n",
        "  policy = np.zeros(NUM_STATES, dtype=int)\n",
        "  for state in range(NUM_STATES):\n",
        "    best_action = 0\n",
        "    best_value = -float('inf')\n",
        "    for action in range(min(state, NUM_STATES - state) + 1):\n",
        "      transition_probs = transition_probability(state, action)\n",
        "      rewards = reward(state, action)\n",
        "      expected_value = np.sum(transition_probs * (rewards + DISCOUNT_FACTOR * value_function))\n",
        "      if expected_value > best_value:\n",
        "        best_value = expected_value\n",
        "        best_action = action\n",
        "    policy[state] = best_action\n",
        "  return policy\n",
        "\n",
        "\n",
        "def policy_iteration():\n",
        "  policy = np.ones(NUM_STATES, dtype=int) * EMPLOYEE_TRANSFER\n",
        "  value_function = np.zeros(NUM_STATES)\n",
        "  while True:\n",
        "    new_value_function = policy_evaluation(policy, value_function)\n",
        "    new_policy = policy_improvement(new_value_function)\n",
        "    if np.array_equal(policy, new_policy):\n",
        "      return new_policy, new_value_function\n",
        "    policy = new_policy\n",
        "    value_function = new_value_function\n",
        "\n",
        "optimal_policy, optimal_value_function = policy_iteration()\n",
        "\n",
        "print(\"Optimal Policy:\")\n",
        "for state, action in enumerate(optimal_policy):\n",
        "  print(f\"State {state} :  Move {action} cars\")\n",
        "\n",
        "print(\"\\nOptimal Value Function:\")\n",
        "print(optimal_value_function)"
      ]
    }
  ]
}